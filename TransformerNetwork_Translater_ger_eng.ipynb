{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerNetwork_Translater_ger_eng.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPfLs44yU3HLjUjtQumIGFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DominikBurkert/PyTorch/blob/master/TransformerNetwork_Translater_ger_eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72Ip_a67PSvE"
      },
      "source": [
        "Erstmal UTILS ausführen -> ToDO sollte noch in neues File ausgelagert werden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "GPTSU6esWadh",
        "outputId": "9e43ad7f-9c0f-4656-9022-7c32c6dc946b"
      },
      "source": [
        "pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 13.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.9.0\n",
            "    Uninstalling torchtext-0.9.0:\n",
            "      Successfully uninstalled torchtext-0.9.0\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re2PH9t1PXxk"
      },
      "source": [
        "import torch\r\n",
        "from torchtext.data.metrics import bleu_score\r\n",
        "import spacy\r\n",
        "import sys\r\n",
        "\r\n",
        "\r\n",
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\r\n",
        "    # Load german tokenizer\r\n",
        "    spacy_ger = spacy.load(\"de\")\r\n",
        "\r\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\r\n",
        "    if type(sentence) == str:\r\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\r\n",
        "    tokens.insert(0, german.init_token)\r\n",
        "    tokens.append(german.eos_token)\r\n",
        "\r\n",
        "    # Go through each german token and convert to an index\r\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    # Convert to Tensor\r\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\r\n",
        "    for i in range(max_length):\r\n",
        "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            output = model(sentence_tensor, trg_tensor)\r\n",
        "\r\n",
        "        best_guess = output.argmax(2)[-1, :].item()\r\n",
        "        outputs.append(best_guess)\r\n",
        "\r\n",
        "        if best_guess == english.vocab.stoi[\"<eos>\"]:\r\n",
        "            break\r\n",
        "\r\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\r\n",
        "    # remove start token\r\n",
        "    return translated_sentence[1:]\r\n",
        "\r\n",
        "\r\n",
        "def bleu(data, model, german, english, device):\r\n",
        "    targets = []\r\n",
        "    outputs = []\r\n",
        "\r\n",
        "    for example in data:\r\n",
        "        src = vars(example)[\"src\"]\r\n",
        "        trg = vars(example)[\"trg\"]\r\n",
        "\r\n",
        "        prediction = translate_sentence(model, src, german, english, device)\r\n",
        "        prediction = prediction[:-1]  # remove <eos> token\r\n",
        "\r\n",
        "        targets.append([trg])\r\n",
        "        outputs.append(prediction)\r\n",
        "\r\n",
        "    return bleu_score(outputs, targets)\r\n",
        "\r\n",
        "\r\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\r\n",
        "    print(\"=> Saving checkpoint\")\r\n",
        "    torch.save(state, filename)\r\n",
        "\r\n",
        "\r\n",
        "def load_checkpoint(checkpoint, model, optimizer):\r\n",
        "    print(\"=> Loading checkpoint\")\r\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\r\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM1x-jsgKMEa"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HilQNdjHKIwh"
      },
      "source": [
        "\"\"\"\r\n",
        "Created on Sat Jan 23 12:39:43 2021\r\n",
        "\r\n",
        "@author: DBURKER\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import spacy #für vokabeln und tokenisierung\r\n",
        "import os\r\n",
        "#from utils import *\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4NqUp6aFwkX"
      },
      "source": [
        "Prüfen ob Zugriff auf eine Grafikkarte vorhanden ist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X6kOJVRFwM_",
        "outputId": "cd3698b6-ec21-4fd8-8e6f-d92225513f71"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.test.gpu_device_name())\r\n",
        "# wenn nicht zugriff auf gpu da ist -> laufzeit -> laufzeit ändern -> gpu auswählen\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "Wed Mar 10 13:04:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    58W / 149W |    124MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJAjvgQZPyL"
      },
      "source": [
        "DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2-l1mQ_K-iU"
      },
      "source": [
        "Install the required languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlQuBtEPKj0K",
        "outputId": "2068225c-2983-4a24-8373-541a7c04912e"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=6d9b94aad5bce2f8b138e8478c5cd8f6f37eded4706bfb516709b46c44455060\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5s2ax6kj/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y3lvDrSZPG0"
      },
      "source": [
        "#als erstes werden die Vokabeln geladen\r\n",
        "spacy_ger = spacy.load(\"de\")\r\n",
        "spacy_eng = spacy.load(\"en\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmG9VCPuPa2z"
      },
      "source": [
        "from google.colab import output\r\n",
        "#I don't know why nbextensions don't work with python3.6 \r\n",
        "with output.temporary():\r\n",
        "  !pip install --upgrade git+https://github.com/Kreijstal/colab_inspector.git \r\n",
        "  !python2.7 -m pip install --upgrade git+https://github.com/blois/colab_inspector.git #yes, really.\r\n",
        "  !jupyter nbextension install --py inspector\r\n",
        "\r\n",
        "import inspector\r\n",
        "\r\n",
        "# open a scratch cell (Ctrl+Alt+N)\r\n",
        "# run there\r\n",
        "# inspector.watch_globals()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jh0NbayGLQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8531c620-84af-4071-a69e-ede26570f13d"
      },
      "source": [
        "\r\n",
        "\"\"\"\r\n",
        "DATA PREPROCESSING\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "#Tokenizer wird angewendet\r\n",
        "def tokenize_ger(text):\r\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_eng(text):\r\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]\r\n",
        "\r\n",
        "german = Field(tokenize = tokenize_ger, lower = True, init_token = \"<sos>\", eos_token = \"<eos>\")\r\n",
        "english = Field(tokenize = tokenize_eng, lower = True, init_token = \"<sos>\", eos_token = \"<eos>\")\r\n",
        "\r\n",
        "\r\n",
        "#load train data, valid data and test data\r\n",
        "train_data, valid_data, test_data = Multi30k.splits(\r\n",
        "    exts = (\".de\", \".en\"), fields = (german, english)\r\n",
        ")\r\n",
        "\r\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=2)\r\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\r\n",
        "#mehr infos dazu: https://torchtext.readthedocs.io/en/latest/datasets.html\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rtraining.tar.gz:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 6.48MB/s]\n",
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.84MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n",
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.62MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvWfCGgpOKjW"
      },
      "source": [
        "Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaAmxRCROLF4"
      },
      "source": [
        "\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "TRANSFORMER\r\n",
        "\"\"\"\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(\r\n",
        "            self,\r\n",
        "            embedding_size, #wird auf 512 gesetzt\r\n",
        "            src_vocab_size, # = len(german.vocab)\r\n",
        "            trg_vocab_size, # = len(english.vocab)\r\n",
        "            src_pad_idx,\r\n",
        "            #anzahl an heads wird für den attention-mechanismus benötigt\r\n",
        "            num_heads, #wenn =8, dann ist die head_size = 512/8 = 64\r\n",
        "            num_encoder_layers,\r\n",
        "            num_decoder_layers,\r\n",
        "            forward_expansion,\r\n",
        "            dropout,\r\n",
        "            max_len, #max_len of german.vocab bzw. english.vocab\r\n",
        "            device\r\n",
        "        ):\r\n",
        "            super(Transformer, self).__init__()\r\n",
        "            #Worteinbettung = Wörter rein -> Vektoren raus\r\n",
        "            self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\r\n",
        "            self.src_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "            self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\r\n",
        "            self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\r\n",
        "            self.device = device\r\n",
        "            \r\n",
        "            #create transformer (from pytorch)\r\n",
        "            self.transformer = nn.Transformer(\r\n",
        "                embedding_size,\r\n",
        "                num_heads,\r\n",
        "                num_encoder_layers,\r\n",
        "                num_decoder_layers,\r\n",
        "                forward_expansion,\r\n",
        "                dropout\r\n",
        "            )\r\n",
        "            self.fc_out =  nn.Linear(embedding_size, trg_vocab_size)\r\n",
        "            self.dropout = nn.Dropout(dropout)\r\n",
        "            self.src_pad_idx = src_pad_idx \r\n",
        "        \r\n",
        "    #maskierung \r\n",
        "    def make_src_mask(self, src):\r\n",
        "        #warum transpose? \r\n",
        "        # src shape ist: (src_len, N) aber wir brauchen (N, src_len)\r\n",
        "        src_mask = src.transpose(0,1) == self.src_pad_idx\r\n",
        "        #src shape: (N, src_len)\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def forward(self, src, trg):\r\n",
        "        src_seq_length, N = src.shape\r\n",
        "        trg_seq_length, N = trg.shape\r\n",
        "        \r\n",
        "        src_positions = (\r\n",
        "            torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length, N).to(self.device)\r\n",
        "        )\r\n",
        "        \r\n",
        "        trg_positions = (\r\n",
        "            torch.arange(0, trg_seq_length).unsqueeze(1).expand(trg_seq_length, N).to(self.device)\r\n",
        "        )\r\n",
        "        \r\n",
        "        embed_src = self.dropout(\r\n",
        "           (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\r\n",
        "        )\r\n",
        "        \r\n",
        "        embed_trg = self.dropout(\r\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\r\n",
        "        )\r\n",
        "        \r\n",
        "        src_padding_mask = self.make_src_mask(src)\r\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(self.device)\r\n",
        "        \r\n",
        "        out = self.transformer(\r\n",
        "            embed_src,\r\n",
        "            embed_trg,\r\n",
        "            src_key_padding_mask = src_padding_mask,\r\n",
        "            tgt_mask = trg_mask)\r\n",
        "        \r\n",
        "        \r\n",
        "        out = self.fc_out(out)\r\n",
        "        return out\r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "bQeRtVgnVTdb",
        "outputId": "4f1aeb83-636c-4e70-a0c8-0ea3f6633f8a"
      },
      "source": [
        "if load_model:\r\n",
        "    load_checkpoint(torch.load(\"my_ceckpoint.pth.tar\"), model, optimizer)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b0fec7c74678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_ceckpoint.pth.tar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWxw6Ko1XrCl"
      },
      "source": [
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpp2YaN6ZJdk",
        "outputId": "56916262-bc32-4ac7-d260-8e61b11dcfb7"
      },
      "source": [
        "state_dict2 = torch.load('checkpoint.pth')\r\n",
        "print(state_dict2.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['src_word_embedding.weight', 'src_position_embedding.weight', 'trg_word_embedding.weight', 'trg_position_embedding.weight', 'transformer.encoder.layers.0.self_attn.in_proj_weight', 'transformer.encoder.layers.0.self_attn.in_proj_bias', 'transformer.encoder.layers.0.self_attn.out_proj.weight', 'transformer.encoder.layers.0.self_attn.out_proj.bias', 'transformer.encoder.layers.0.linear1.weight', 'transformer.encoder.layers.0.linear1.bias', 'transformer.encoder.layers.0.linear2.weight', 'transformer.encoder.layers.0.linear2.bias', 'transformer.encoder.layers.0.norm1.weight', 'transformer.encoder.layers.0.norm1.bias', 'transformer.encoder.layers.0.norm2.weight', 'transformer.encoder.layers.0.norm2.bias', 'transformer.encoder.layers.1.self_attn.in_proj_weight', 'transformer.encoder.layers.1.self_attn.in_proj_bias', 'transformer.encoder.layers.1.self_attn.out_proj.weight', 'transformer.encoder.layers.1.self_attn.out_proj.bias', 'transformer.encoder.layers.1.linear1.weight', 'transformer.encoder.layers.1.linear1.bias', 'transformer.encoder.layers.1.linear2.weight', 'transformer.encoder.layers.1.linear2.bias', 'transformer.encoder.layers.1.norm1.weight', 'transformer.encoder.layers.1.norm1.bias', 'transformer.encoder.layers.1.norm2.weight', 'transformer.encoder.layers.1.norm2.bias', 'transformer.encoder.layers.2.self_attn.in_proj_weight', 'transformer.encoder.layers.2.self_attn.in_proj_bias', 'transformer.encoder.layers.2.self_attn.out_proj.weight', 'transformer.encoder.layers.2.self_attn.out_proj.bias', 'transformer.encoder.layers.2.linear1.weight', 'transformer.encoder.layers.2.linear1.bias', 'transformer.encoder.layers.2.linear2.weight', 'transformer.encoder.layers.2.linear2.bias', 'transformer.encoder.layers.2.norm1.weight', 'transformer.encoder.layers.2.norm1.bias', 'transformer.encoder.layers.2.norm2.weight', 'transformer.encoder.layers.2.norm2.bias', 'transformer.encoder.norm.weight', 'transformer.encoder.norm.bias', 'transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.layers.1.self_attn.in_proj_weight', 'transformer.decoder.layers.1.self_attn.in_proj_bias', 'transformer.decoder.layers.1.self_attn.out_proj.weight', 'transformer.decoder.layers.1.self_attn.out_proj.bias', 'transformer.decoder.layers.1.multihead_attn.in_proj_weight', 'transformer.decoder.layers.1.multihead_attn.in_proj_bias', 'transformer.decoder.layers.1.multihead_attn.out_proj.weight', 'transformer.decoder.layers.1.multihead_attn.out_proj.bias', 'transformer.decoder.layers.1.linear1.weight', 'transformer.decoder.layers.1.linear1.bias', 'transformer.decoder.layers.1.linear2.weight', 'transformer.decoder.layers.1.linear2.bias', 'transformer.decoder.layers.1.norm1.weight', 'transformer.decoder.layers.1.norm1.bias', 'transformer.decoder.layers.1.norm2.weight', 'transformer.decoder.layers.1.norm2.bias', 'transformer.decoder.layers.1.norm3.weight', 'transformer.decoder.layers.1.norm3.bias', 'transformer.decoder.layers.2.self_attn.in_proj_weight', 'transformer.decoder.layers.2.self_attn.in_proj_bias', 'transformer.decoder.layers.2.self_attn.out_proj.weight', 'transformer.decoder.layers.2.self_attn.out_proj.bias', 'transformer.decoder.layers.2.multihead_attn.in_proj_weight', 'transformer.decoder.layers.2.multihead_attn.in_proj_bias', 'transformer.decoder.layers.2.multihead_attn.out_proj.weight', 'transformer.decoder.layers.2.multihead_attn.out_proj.bias', 'transformer.decoder.layers.2.linear1.weight', 'transformer.decoder.layers.2.linear1.bias', 'transformer.decoder.layers.2.linear2.weight', 'transformer.decoder.layers.2.linear2.bias', 'transformer.decoder.layers.2.norm1.weight', 'transformer.decoder.layers.2.norm1.bias', 'transformer.decoder.layers.2.norm2.weight', 'transformer.decoder.layers.2.norm2.bias', 'transformer.decoder.layers.2.norm3.weight', 'transformer.decoder.layers.2.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'fc_out.weight', 'fc_out.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ic3jHd5ZZvm",
        "outputId": "846fdb03-a0cc-4344-d154-23593eafdbca"
      },
      "source": [
        "ls -l\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 3 root root 4096 Mar  5 11:41 \u001b[0m\u001b[01;34mruns\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Mar  1 14:35 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQS5h0HFO6ZE",
        "outputId": "bd9028d8-6d30-4506-e284-14ddbec7dfc0"
      },
      "source": [
        "\"\"\" \r\n",
        "\r\n",
        "TRAINING\r\n",
        "\"\"\"  \r\n",
        "#set up the training phase\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "load_model = True\r\n",
        "save_model = True\r\n",
        "        \r\n",
        "# Training hyperparameters\r\n",
        "num_epochs = 1\r\n",
        "learning_rate = 3e-4\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Model Hyperparameters\r\n",
        "src_vocab_size = len(german.vocab)\r\n",
        "trg_vocab_size = len(english.vocab)\r\n",
        "embedding_size = 512\r\n",
        "num_heads  = 8\r\n",
        "num_encoder_layers = 3\r\n",
        "num_decoder_layers = 3\r\n",
        "dropout = 0.10\r\n",
        "max_len = 100\r\n",
        "forward_expansion = 4\r\n",
        "src_pad_idx = english.vocab.stoi[\"<pad>\"]\r\n",
        "\r\n",
        "#tensorboard for nice plots\r\n",
        "writer = SummaryWriter(\"runs/loss_plot\")\r\n",
        "step = 0\r\n",
        "\r\n",
        "#create the iterator\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data),\r\n",
        "    batch_size=batch_size,\r\n",
        "    sort_within_batch=True,\r\n",
        "    sort_key=lambda x: len(x.src),\r\n",
        "    device=device,\r\n",
        " )\r\n",
        "\r\n",
        "model = Transformer(\r\n",
        "    embedding_size, \r\n",
        "    src_vocab_size, \r\n",
        "    trg_vocab_size, \r\n",
        "    src_pad_idx, \r\n",
        "    num_heads, \r\n",
        "    num_encoder_layers, \r\n",
        "    num_decoder_layers, \r\n",
        "    forward_expansion, \r\n",
        "    dropout, max_len, \r\n",
        "    device\r\n",
        " ).to(device)\r\n",
        "\r\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\r\n",
        "\r\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\r\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = pad_idx)\r\n",
        "\r\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformer(\n",
            "  (src_word_embedding): Embedding(7855, 512)\n",
            "  (src_position_embedding): Embedding(100, 512)\n",
            "  (trg_word_embedding): Embedding(5893, 512)\n",
            "  (trg_position_embedding): Embedding(100, 512)\n",
            "  (transformer): Transformer(\n",
            "    (encoder): TransformerEncoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): TransformerEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): TransformerDecoder(\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): TransformerDecoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (multihead_attn): MultiheadAttention(\n",
            "            (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (linear1): Linear(in_features=512, out_features=4, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (linear2): Linear(in_features=4, out_features=512, bias=True)\n",
            "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout2): Dropout(p=0.1, inplace=False)\n",
            "          (dropout3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Lui6SfMqhP"
      },
      "source": [
        "if load_model:\r\n",
        "    #load_checkpoint(torch.load(\"checkpoint.pth\"), model, optimizer)\r\n",
        "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\r\n",
        "    \r\n",
        "sentence = \"ein pferd geht unter einer brücke neben einem boot.\"\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\r\n",
        "    \r\n",
        "    if save_model:\r\n",
        "        checkpoint = {\r\n",
        "            \"state_dict\" : model.state_dict(),\r\n",
        "            \"optimizer\" : optimizer.state_dict(),\r\n",
        "        }\r\n",
        "        \r\n",
        "        save_checkpoint(checkpoint)\r\n",
        "        \r\n",
        "    model.eval()\r\n",
        "    translated_sentence = translate_sentence(\r\n",
        "        model, sentence, german, english, device, max_length=100\r\n",
        "    )\r\n",
        "    \r\n",
        "    print(f\"Translated example sentence \\n {translated_sentence}\")\r\n",
        "    model.train()\r\n",
        "\r\n",
        "\r\n",
        "    for batch_idx, batch in enumerate(train_iterator):\r\n",
        "        inp_data = batch.src.to(device)\r\n",
        "        target = batch.trg.to(device)\r\n",
        "        \r\n",
        "        #forward prop\r\n",
        "        output = model(inp_data, target[:-1])\r\n",
        "        \r\n",
        "        output = output.reshape(-1, output.shape[2])\r\n",
        "        target = target[1:].reshape(-1)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        loss = criterion(output, target)\r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), max_norm = 1)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step = step)\r\n",
        "        step += 1\r\n",
        "        \r\n",
        "    #this is gonna take a while\r\n",
        "    score = bleu(test_data, model, german, english, device)\r\n",
        "    print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}